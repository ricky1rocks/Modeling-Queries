{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import vertica_python\n",
    "import os\n",
    "import datetime as dt\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from math import sqrt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import _pickle as cPickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/centos/notebooks/Shashank/rto_testing/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = ['code', 'order_created_date', 'address_length', 'address_has_numeric',\n",
    "\t\t\t\t'dest_pincode', 'subcategory_id', \n",
    "\t\t\t\t'bucket_id', 'user_del', 'user_del_ship', \n",
    "\t\t\t\t'city_att_14', 'city_del_14', 'pin_att_14', 'pin_del_14',\n",
    "\t\t\t\t'courier_group', 'rto', 'Same_SUPC_Dup', \n",
    "\t\t\t\t'Same_Subcat_Dup', 'ITR', 'del_mob_wa_sent_success', 'del_mob_wa_del', 'del_mob_wa_read', \n",
    "\t\t\t\t'reg_mob_wa_sent_success', 'reg_mob_wa_del', 'reg_mob_wa_read', 'add1_del', 'add2_del']\n",
    "\n",
    "select_vars = ','.join(col_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_info = dict(host='10.65.0.201', port=5433, database='snapdealdwh', user='shashank.jain03',password='Sachin@200')\n",
    "\n",
    "conn = vertica_python.connect(**conn_info)\n",
    "cur = conn.cursor()\n",
    "query_fetch = \"select %s from analytics_logistics.ys_junfull_data_fin where shipped = 1 and subo_shipping_method_code = 'COD';\" % (select_vars)\n",
    "cur.execute(query_fetch)\n",
    "data = cur.fetchall()\n",
    "conn.close()\n",
    "\n",
    "mydata = pd.DataFrame(data = data, columns = col_names)\n",
    "mydata.to_csv('rto_data_0821.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata.tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata = pd.read_csv('rto_data_0821.csv')\n",
    "mydata = mydata.rename(columns = {'address_length': 'add_length', 'address_has_numeric': 'is_num'})\n",
    "mydata['order_created_date'] = pd.to_datetime(mydata['order_created_date'], infer_datetime_format=True) \n",
    "mydata['order_created_date'] = mydata['order_created_date'].dt.date\n",
    "mydata['is_num'] = np.where(mydata['is_num'] == 'Yes', 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata['is_num'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata['add_length'] = mydata['add_length'].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dividing data in train and test\n",
    "\n",
    "train = mydata.loc[mydata['order_created_date'] <= dt.date(2021, 6, 15),:]\n",
    "test = mydata.loc[mydata['order_created_date'] > dt.date(2021, 6, 15),:]\n",
    "\n",
    "# creating additional variables\n",
    "\n",
    "train = train.drop(columns = ['order_created_date', 'code'])\n",
    "train = train.dropna(subset = ['subcategory_id', 'bucket_id'])\n",
    "train[['subcategory_id', 'bucket_id']] = train[['subcategory_id', 'bucket_id']].astype('int64')\n",
    "\n",
    "cols = ['user_del_ship', 'pin_att_14', 'city_att_14']\n",
    "train[cols] = train[cols].replace(0,np.nan)\n",
    "\n",
    "train.loc[train['user_del_ship'].isna(), 'user_del'] = np.nan\n",
    "\n",
    "train['del_per'] = np.where(train['user_del_ship'] != 0, train['user_del']*100/train['user_del_ship'], np.nan)\n",
    "\n",
    "train['pin_fasr_14'] = np.where(~train['pin_att_14'].isna(), train['pin_del_14']*100/train['pin_att_14'], np.nan)\n",
    "train['city_fasr_14'] = np.where(~train['city_att_14'].isna(), train['city_del_14']*100/train['city_att_14'], np.nan)\n",
    "\n",
    "train[['Same_SUPC_Dup', 'Same_Subcat_Dup']] = train[['Same_SUPC_Dup', 'Same_Subcat_Dup']].fillna(0)\n",
    "train['ITR'] = train['ITR'].fillna(0)\n",
    "\n",
    "train['same_supc'] = np.where(train['Same_SUPC_Dup'] > 0, 1, 0)\n",
    "train['same_subcat'] = np.where(train['Same_Subcat_Dup'] > 0, 1, 0)\n",
    "\n",
    "train['three_80'] = np.where((train['user_del_ship'] > 3) & (train['del_per'] < 20), 1, 0)\n",
    "train['five_70'] = np.where((train['user_del_ship'] > 5) & (train['del_per'] < 30), 1, 0)\n",
    "\n",
    "train.loc[train['user_del_ship'].isna(), 'three_80'] = np.nan\n",
    "train.loc[train['user_del_ship'].isna(), 'five_70'] = np.nan\n",
    "\n",
    "\n",
    "top_vars = ['del_per', 'pin_fasr_14',\n",
    "\t\t\t\t'add_length', 'subcategory_id',\n",
    "\t\t\t\t'city_fasr_14', 'bucket_id', 'dest_pincode', 'user_del',\n",
    "\t\t\t\t'is_num', 'same_supc', 'same_subcat', 'ITR', 'three_80', 'five_70', 'user_del_ship', \n",
    "\t\t\t\t'del_mob_wa_sent_success', 'del_mob_wa_del', 'del_mob_wa_read', \n",
    "\t\t\t\t'reg_mob_wa_sent_success', 'reg_mob_wa_del', 'reg_mob_wa_read']\n",
    "\n",
    "\n",
    "train = train[top_vars + ['rto']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test = test.dropna(subset = ['subcategory_id', 'bucket_id'])\n",
    "test[['subcategory_id', 'bucket_id']] = test[['subcategory_id', 'bucket_id']].astype('int64')\n",
    "\n",
    "test[cols] = test[cols].replace(0,np.nan)\n",
    "\n",
    "test.loc[test['user_del_ship'].isna(), 'user_del'] = np.nan\n",
    "\n",
    "test['del_per'] = np.where(test['user_del_ship'] != 0, test['user_del']*100/test['user_del_ship'], np.nan)\n",
    "\n",
    "test['pin_fasr_14'] = np.where(~test['pin_att_14'].isna(), test['pin_del_14']*100/test['pin_att_14'], np.nan)\n",
    "test['city_fasr_14'] = np.where(~test['city_att_14'].isna(), test['city_del_14']*100/test['city_att_14'], np.nan)\n",
    "\n",
    "test[['Same_SUPC_Dup', 'Same_Subcat_Dup']] = test[['Same_SUPC_Dup', 'Same_Subcat_Dup']].fillna(0)\n",
    "test['ITR'] = test['ITR'].fillna(0)\n",
    "\n",
    "test['same_supc'] = np.where(test['Same_SUPC_Dup'] > 0, 1, 0)\n",
    "test['same_subcat'] = np.where(test['Same_Subcat_Dup'] > 0, 1, 0)\n",
    "\n",
    "test['three_80'] = np.where((test['user_del_ship'] > 3) & (test['del_per'] < 20), 1, 0)\n",
    "test['five_70'] = np.where((test['user_del_ship'] > 5) & (test['del_per'] < 30), 1, 0)\n",
    "\n",
    "test.loc[test['user_del_ship'].isna(), 'three_80'] = np.nan\n",
    "test.loc[test['user_del_ship'].isna(), 'five_70'] = np.nan\n",
    "\n",
    "out_of_time = test[['order_created_date', 'code', 'rto']].copy()\n",
    "test = test[top_vars + ['rto']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_vars = ['subcategory_id', 'bucket_id', 'dest_pincode']\n",
    "train[cat_vars] = train[cat_vars].astype('str')\n",
    "test[cat_vars] = test[cat_vars].astype('str')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combining long tail of categorical variables\n",
    "\n",
    "club_vars = ['subcategory_id', 'bucket_id', 'dest_pincode']\n",
    "\n",
    "def club_categories(x,n = 100):\n",
    "    freq = x.value_counts()\n",
    "    less_freq_cats = list(freq[freq < n].keys())\n",
    "    x[x.isin(less_freq_cats)] = 'other'\n",
    "    return(x)\n",
    "\n",
    "train[club_vars] = train[club_vars].apply(club_categories, axis = 0)\n",
    "\n",
    "for var in club_vars:\n",
    "\ttrain_values = train[var].unique()\n",
    "\ttest.loc[~test[var].isin(train_values), var] = 'other'\n",
    "\n",
    "\n",
    "# replacing categorical data with weight of evidence of respective categories\n",
    "\n",
    "def iv_variable(data, indep, dep):\n",
    "\n",
    "\tsub_data = data[[indep, dep]].copy()\n",
    "\tevent = sub_data[dep].sum()\n",
    "\tnon_event = sub_data.shape[0] - event\n",
    "\tiv_data = sub_data.groupby(indep).agg(['sum', 'size']).rename(columns = {'sum': 'event', 'size': 'total'})\n",
    "\tiv_data.columns = iv_data.columns.droplevel(level=0)\n",
    "\tiv_data = iv_data.reset_index(drop = False)\n",
    "\tiv_data['non_event'] = iv_data['total'] - iv_data['event'] \n",
    "\tiv_data['per_event'] = iv_data['event']/event\n",
    "\tiv_data['per_non_event'] = iv_data['non_event']/non_event\n",
    "\tiv_data['woe'] = np.log(((iv_data['non_event'] + 0.5)/non_event)/((iv_data['event'] + 0.5)/event)) * (iv_data['per_non_event'] - iv_data['per_event'])\n",
    "\tiv_data['woe'] = 100*iv_data['woe']\n",
    "# \tiv_data['cat_rto'] = iv_data['event']/iv_data['total']\n",
    "# \tbase_rto = event/(event + non_event)\n",
    "# \tiv_data['woe'] = np.where(iv_data['cat_rto'] < base_rto, iv_data['cat_rto']*(-1.0), iv_data['cat_rto'])\n",
    "\tiv_data = iv_data[[indep, 'woe']]\n",
    "\treturn(iv_data)\n",
    "\n",
    "\n",
    "woe_dict = {}\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for var in cat_vars:\n",
    "\tiv_var = iv_variable(train, var, 'rto')\n",
    "\twoe_dict[var] = dict(zip(iv_var[var], iv_var['woe']))\n",
    "\ttrain = pd.merge(train, iv_var, how = 'left', on = var).drop(columns = [var]).rename(columns = {'woe': var})\n",
    "\ttest = pd.merge(test, iv_var, how = 'left', on = var).drop(columns = [var]).rename(columns = {'woe': var})\n",
    "\n",
    "end = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imputing missing values with a fixed large negative numeric value so that it will be treated as a different category\n",
    "\n",
    "train.fillna(-99999, inplace = True)\n",
    "test.fillna(-99999, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dividing training into training and validation data\n",
    "\n",
    "X, y = train.drop(columns = ['rto', 'del_mob_wa_sent_success', 'del_mob_wa_del', 'del_mob_wa_read', 'reg_mob_wa_sent_success', 'reg_mob_wa_del', 'reg_mob_wa_read']), train['rto']\n",
    "train_x, valid_x, train_y, valid_y = train_test_split(X, y, test_size = 0.2, random_state = 163)\n",
    "\n",
    "test_x, test_y = test.drop(columns = ['rto', 'del_mob_wa_sent_success', 'del_mob_wa_del', 'del_mob_wa_read', 'reg_mob_wa_sent_success', 'reg_mob_wa_del', 'reg_mob_wa_read']), test['rto']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training the model\n",
    "\n",
    "xgb_clf = xgb.XGBClassifier(max_depth = 6,\n",
    "                           min_child_weight = 1,\n",
    "                           learning_rate = 0.1,\n",
    "                           n_estimators = 200,\n",
    "                           objective = 'binary:logistic',\n",
    "                           gamma = 5,\n",
    "                           n_jobs = 30)\n",
    "\n",
    " \n",
    "xgb_clf.fit(train_x, train_y, eval_metric = 'error',\n",
    "            eval_set = [(train_x, train_y), (valid_x, valid_y)], early_stopping_rounds = 50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting variable importance\n",
    "\n",
    "var_imp = xgb_clf.get_booster().get_score(importance_type = 'total_gain')\n",
    "imp_data = pd.DataFrame({'feature': list(var_imp.keys()), 'importance': list(var_imp.values())})\n",
    "imp_data = imp_data.sort_values(by = 'importance', ascending = False)\n",
    "imp_data.importance = imp_data.importance/np.sum(imp_data.importance)\n",
    "imp_data.reset_index(drop = True, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting test accuracy\n",
    "\n",
    "predicted_values = xgb_clf.predict_proba(test_x)[:,1]\n",
    "predicted_class = np.where(predicted_values > 0.5, 1, 0)\n",
    "test_accuracy = np.sum(test_y == predicted_class)/len(test_y)\n",
    "\n",
    "print('test accuracy: %.3f' % (test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting test accuracy\n",
    "\n",
    "predicted_values = xgb_clf.predict_proba(test_x)[:,1]\n",
    "predicted_class = np.where(predicted_values > 0.5, 1, 0)\n",
    "test_accuracy = np.sum(test_y == predicted_class)/len(test_y)\n",
    "\n",
    "print('test accuracy: %.3f' % (test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting test accuracy (new woe)\n",
    "\n",
    "predicted_values = xgb_clf.predict_proba(test_x)[:,1]\n",
    "predicted_class = np.where(predicted_values > 0.5, 1, 0)\n",
    "test_accuracy = np.sum(test_y == predicted_class)/len(test_y)\n",
    "\n",
    "print('test accuracy: %.3f' % (test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['rto_prob'] = predicted_values\n",
    "test.to_csv('rto_probs_june21.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.replace(-99999.0, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indep = 'del_per'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def var_imp(indep, method = 'cut', q = 10):\n",
    "    sub_data = test[[indep, 'rto', 'rto_prob']].copy()\n",
    "    if method == 'cut':\n",
    "        sub_data['decile'] = pd.cut(sub_data[indep], bins = 10)\n",
    "    else:\n",
    "        sub_data['decile'] = pd.qcut(sub_data[indep], q = q, duplicates = 'drop')\n",
    "          \n",
    "    sub_data['decile'] = sub_data['decile'].astype('str')\n",
    "\n",
    "    out = sub_data.groupby('decile').agg(\n",
    "        count = ('rto_prob', 'count'),\n",
    "        rto_prob_mean = ('rto_prob', 'mean'),\n",
    "        rto_actual = ('rto', 'mean'),   \n",
    "    ).reset_index()\n",
    "\n",
    "    out['salience'] = np.round(out['count']*100/np.sum(out['count']),2)\n",
    "    out = out.rename(columns = {'decile': indep})\n",
    "    out['rto_prob_mean'] = np.round(out['rto_prob_mean'],2)\n",
    "    out['rto_prob_mean'] = np.round(out['rto_prob_mean'],2)\n",
    "    return(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_imp('del_per')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_imp('pin_fasr_14')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_imp('add_length', method = 'qcut')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_imp('ITR', method = 'qcut', q = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_of_time['rto_prob'] = predicted_values\n",
    "# out_of_time.to_csv('rto_probs_3_80_june21.csv', index = False)\n",
    "# out_of_time = pd.read_csv('rto_probs_june21.csv')\n",
    "\n",
    "out_of_time['decile'] = pd.cut(out_of_time['rto_prob'], bins = np.arange(0,1.01, 0.05))\n",
    "out_of_time['decile'] = out_of_time['decile'].astype('str').str.replace(' ', '')\n",
    "\n",
    "out = out_of_time.groupby(['decile'])['rto'].agg(['size', 'sum']).reset_index(drop = False).rename(columns = {'size': 'count', 'sum': 'rto'})\n",
    "out['rto_per'] = out['rto']/out['count']\n",
    "out['salience'] = out['count']/out_of_time.shape[0]\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_of_time['rto_prob'] = predicted_values\n",
    "# out_of_time.to_csv('rto_probs_3_80_june21.csv', index = False)\n",
    "# out_of_time = pd.read_csv('rto_probs_june21.csv')\n",
    "\n",
    "out_of_time['decile'] = pd.cut(out_of_time['rto_prob'], bins = np.arange(0,1.01, 0.05))\n",
    "out_of_time['decile'] = out_of_time['decile'].astype('str').str.replace(' ', '')\n",
    "\n",
    "out = out_of_time.groupby(['decile'])['rto'].agg(['size', 'sum']).reset_index(drop = False).rename(columns = {'size': 'count', 'sum': 'rto'})\n",
    "out['rto_per'] = out['rto']/out['count']\n",
    "out['salience'] = out['count']/out_of_time.shape[0]\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with new woe\n",
    "\n",
    "out_of_time['rto_prob'] = predicted_values\n",
    "# out_of_time.to_csv('rto_probs_3_80_june21.csv', index = False)\n",
    "# out_of_time = pd.read_csv('rto_probs_june21.csv')\n",
    "\n",
    "out_of_time['decile'] = pd.cut(out_of_time['rto_prob'], bins = np.arange(0,1.01, 0.05))\n",
    "out_of_time['decile'] = out_of_time['decile'].astype('str').str.replace(' ', '')\n",
    "\n",
    "out = out_of_time.groupby(['decile'])['rto'].agg(['size', 'sum']).reset_index(drop = False).rename(columns = {'size': 'count', 'sum': 'rto'})\n",
    "out['rto_per'] = out['rto']/out['count']\n",
    "out['salience'] = out['count']/out_of_time.shape[0]\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
